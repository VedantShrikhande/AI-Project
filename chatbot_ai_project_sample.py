# -*- coding: utf-8 -*-
"""Chatbot AI Project Sample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1522hFoEd_8xXeW4RYP_unJriyZMvWXP7
"""

import re
import pandas as pd
import spacy
import streamlit as st
from transformers import pipeline
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
import logging
import os

# ----- PII Detection (Regex & NER) -----
PII_PATTERNS = {
    'email': re.compile(r'\b[\w\.-]+?@\w+?\.\w{2,4}\b'),
    'phone': re.compile(r'\b(?:\+\d{1,3})?[\s\-]?\(?\d{2,4}\)?[\s\-]?\d{3,5}[\s\-]?\d{4,6}\b'),
    'ssn': re.compile(r'\b\d{3}-\d{2}-\d{4}\b'),
    'credit_card': re.compile(r'\b(?:\d[ -]*?){13,16}\b'),
    'address': re.compile(r'\b\d{1,5}\s[\w\s]{1,20}(?:Street|St|Avenue|Ave|Boulevard|Blvd|Road|Rd|Lane|Ln|Drive|Dr)\b', re.I),
}

def detect_pii_regex(text):
    """Return list of PII types found with regex."""
    return [entity for entity, pattern in PII_PATTERNS.items() if pattern.search(text)]

@st.cache_resource
def load_spacy():
    return spacy.load("en_core_web_sm")
nlp = load_spacy()

def detect_pii_ner(text):
    doc = nlp(text)
    return [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in {"PERSON", "GPE", "ORG"}]

def contains_pii(text):
    return bool(detect_pii_regex(text) or detect_pii_ner(text))

# ----- Hate Speech Classifier -----
@st.cache_resource
def load_hate_classifier():
    df = pd.read_csv('HateSpeechDataset.csv')
    X = df['Content']
    y = df['Label']
    vectorizer = CountVectorizer(stop_words='english')
    X_vec = vectorizer.fit_transform(X)
    X_train, _, y_train, _ = train_test_split(X_vec, y, test_size=0.2, random_state=42)
    clf = LogisticRegression()
    clf.fit(X_train, y_train)
    return vectorizer, clf

vectorizer, clf = load_hate_classifier()

def is_hate_speech(text):
    return clf.predict(vectorizer.transform([text]))[0] == 1

def is_unsafe(text):
    return contains_pii(text) or is_hate_speech(text)

# ----- LLM Integration -----
@st.cache_resource
def load_llm():
    # Example: Use smaller HuggingFace model for demo.
    return pipeline("text-generation", model="distilgpt2")  # replace with Llama-2-7b-chat if available

chatbot = load_llm()

def llm_response(prompt):
    return chatbot(prompt, max_new_tokens=120)[0]['generated_text']

# ----- Streamlit Frontend + Logging -----
LOG_FILE = "chatbot_safety_log.txt"
logger = logging.getLogger("chatbot_logger")
logger.setLevel(logging.INFO)
if not logger.hasHandlers():
    file_handler = logging.FileHandler(LOG_FILE)
    formatter = logging.Formatter("%(asctime)s %(levelname)s: %(message)s")
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

st.set_page_config(page_title="Secure LLM Chatbot", page_icon="ü§ñ")
st.title("üîí Secure LLM Chatbot")
st.write("A privacy-aware chatbot with PII & hate speech filtering.")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Say something..."):
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    response = llm_response(prompt)
    if is_unsafe(response):
        safe_response = "‚ö†Ô∏è Sorry, this response was filtered for safety. Please rephrase your request."
        logger.info(f"BLOCKED | Prompt: '{prompt}' | Response: '{response}'")
    else:
        safe_response = response
        logger.info(f"SAFE | Prompt: '{prompt}' | Response: '{response}'")
    with st.chat_message("assistant"):
        st.markdown(safe_response)
    st.session_state["messages"].append({"role": "assistant", "content": safe_response})

# Option to show/download the log (for admins/audits)
if st.button("Show Filter Log"):
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r") as f:
            st.download_button("Download Log", f, file_name=LOG_FILE)

df_hate_speech = pd.read_csv('HateSpeechDataset.csv')
print(df_hate_speech.columns)